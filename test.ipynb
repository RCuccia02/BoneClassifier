{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a6bb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import pathlib\n",
    "\n",
    "train_images_dir = pathlib.Path(\"./archive/Human Bone Fractures Multi-modal Image Dataset (HBFMID)/Bone Fractures Detection\") / \"train\" / \"images\"\n",
    "train_labes_dir = pathlib.Path(\"./archive/Human Bone Fractures Multi-modal Image Dataset (HBFMID)/Bone Fractures Detection\") / \"train\" / \"labels\"\n",
    "train_images = list(train_images_dir.glob(\"*.jpg\"))\n",
    "\n",
    "class_names = ['Comminuted', 'Greenstick', 'Healthy', 'Linear', 'Oblique Displaced', 'Oblique', 'Segmental', 'Spiral', 'Transverse Displaced', 'Transverse']\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    img = Image.open(train_images[i])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(img.size)\n",
    "    # ax.axis(\"off\")\n",
    "\n",
    "    label_path = train_labes_dir / f\"{train_images[i].stem}.txt\"\n",
    "    if label_path.exists():\n",
    "        with open(label_path, \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        img_width, img_height = img.size\n",
    "        for line in lines:\n",
    "            values = line.strip().split()\n",
    "            class_id = int(values[0])\n",
    "            x_center, y_center, width, height = map(float, values[1:])\n",
    "\n",
    "            x1 = int((x_center - width / 2) * img_width)\n",
    "            y1 = int((y_center - height / 2) * img_height)\n",
    "\n",
    "            box_width = int(width * img_width)\n",
    "            box_height = int(height * img_height)\n",
    "\n",
    "            rect = patches.Rectangle((x1, y1), box_width, box_height, linewidth=2, edgecolor=\"r\", facecolor=\"none\")\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(x1-20, y1-20, class_names[class_id], color=\"r\", fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aebfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")  # Should match your installed CUDA (12.x)\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")  # Must be True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edccc815",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch\n",
    "\n",
    "# Check GPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"GPU name: {torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'}\")  # Show GPU info\n",
    "\n",
    "# Load YOLO model\n",
    "try:\n",
    "    model = YOLO(\"./yolo11m.pt\").to(device)\n",
    "except:\n",
    "    print(\"Custom weights not found, falling back to pretrained YOLOv8\")\n",
    "    model = YOLO(\"yolov8m.pt\").to(device)  # Fallback to standard YOLOv8 medium\n",
    "\n",
    "# Training parameters\n",
    "config = {\n",
    "    \"data\": \"./archive/Human Bone Fractures Multi-modal Image Dataset (HBFMID)/Bone Fractures Detection/data.yaml\",\n",
    "    \"epochs\": 50,  # Increased from 20 as medical imaging often benefits from more epochs\n",
    "    \"imgsz\": 640,\n",
    "    \"batch\": 16 if device == 'cuda' else 4,  # Smaller batch for CPU\n",
    "    \"device\": device,\n",
    "    \"project\": \"yolo_fracture_detection\",\n",
    "    \"name\": \"exp1\",\n",
    "    \"exist_ok\": True,\n",
    "    \"optimizer\": \"AdamW\",  # More modern optimizer\n",
    "    \"lr0\": 0.001,  # Lower initial LR for fine-tuning\n",
    "    \"pretrained\": True,\n",
    "    \"cos_lr\": True,  # Cosine learning rate scheduler\n",
    "    \"weight_decay\": 0.0005,  # Regularization\n",
    "    \"fliplr\": 0.5,  # Horizontal flip augmentation\n",
    "    \"mosaic\": 1.0,  # Mosaic augmentation\n",
    "    \"mixup\": 0.2,  # Mixup augmentation\n",
    "    \"close_mosaic\": 10,  # Disable mosaic last epochs\n",
    "    \"patience\": 15,  # Early stopping patience\n",
    "    \"save_period\": 5,  # Save checkpoint every 5 epochs\n",
    "    \"single_cls\": False,  # Set True if you have only fracture/non-fracture\n",
    "}\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    results = model.train(**config)\n",
    "    print(\"Training completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Training failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d265c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)             # Should be 2.3.0+\n",
    "print(torch.cuda.is_available())    # Should return True\n",
    "print(torch.version.cuda)           # Should show 12.1 (but works with 12.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bbfb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "from torchvision.ops import nms\n",
    "\n",
    "# Dummy data\n",
    "boxes = torch.tensor([[0, 0, 10, 10], [0, 0, 10, 10]], dtype=torch.float32).cuda()\n",
    "scores = torch.tensor([0.9, 0.8], dtype=torch.float32).cuda()\n",
    "\n",
    "# Prova a chiamare NMS\n",
    "output = nms(boxes, scores, 0.5)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
